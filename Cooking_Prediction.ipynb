{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2adc57b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "from sklearn import linear_model\n",
    "import csv\n",
    "import random\n",
    "import string\n",
    "import math\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e95d52d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)\n",
    "\n",
    "def readCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    c = csv.reader(f)\n",
    "    header = next(c)\n",
    "    for l in c:\n",
    "        d = dict(zip(header,l))\n",
    "        yield d['user_id'],d['recipe_id'],d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a17861c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Rating baseline: compute averages for each user, or return the global average if we've never seen the user before\n",
    "\n",
    "allRatings = []\n",
    "userRatings = defaultdict(list)\n",
    "\n",
    "for user,recipe,d in readCSV(\"trainInteractions.csv.gz\"):\n",
    "  r = int(d['rating'])\n",
    "  allRatings.append(r)\n",
    "  userRatings[user].append(r)\n",
    "\n",
    "globalAverage = sum(allRatings) / len(allRatings)\n",
    "userAverage = {}\n",
    "for u in userRatings:\n",
    "  userAverage[u] = sum(userRatings[u]) / len(userRatings[u])\n",
    "\n",
    "predictions = open(\"predictions_Rated.txt\", 'w')\n",
    "for l in open(\"stub_Rated.txt\"):\n",
    "  if l.startswith(\"user_id\"):\n",
    "    #header\n",
    "    predictions.write(l)\n",
    "    continue\n",
    "  u,i = l.strip().split('-')\n",
    "  if u in userAverage:\n",
    "    predictions.write(u + '-' + i + ',' + str(userAverage[u]) + '\\n')\n",
    "  else:\n",
    "    predictions.write(u + '-' + i + ',' + str(globalAverage) + '\\n')\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb2d8d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Would-cook baseline: just rank which recipes are popular and which are not, and return '1' if a recipe is among the top-ranked\n",
    "\n",
    "recipeCount = defaultdict(int)\n",
    "totalCooked = 0\n",
    "\n",
    "for user,recipe,_ in readCSV(\"trainInteractions.csv.gz\"):\n",
    "  recipeCount[recipe] += 1\n",
    "  totalCooked += 1\n",
    "\n",
    "mostPopular = [(recipeCount[x], x) for x in recipeCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "# return1 = set()\n",
    "# count = 0\n",
    "# for ic, i in mostPopular:\n",
    "#   count += ic\n",
    "#   return1.add(i)\n",
    "#   if count > 0.75 * totalCooked: break\n",
    "\n",
    "# predictions = open(\"predictions_Made.txt\", 'w')\n",
    "# for l in open(\"stub_Made.txt\"):\n",
    "#   if l.startswith(\"user_id\"):\n",
    "#     #header\n",
    "#     predictions.write(l)\n",
    "#     continue\n",
    "#   u,i = l.strip().split('-')\n",
    "#   if i in return1:\n",
    "#     predictions.write(u + '-' + i + \",1\\n\")\n",
    "#   else:\n",
    "#     predictions.write(u + '-' + i + \",0\\n\")\n",
    "\n",
    "# predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8803587",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cook-time prediction baseline: Regress based on the length of the instructions\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for d in readGz(\"trainRecipes.json.gz\"):\n",
    "  X.append([1,len(d['steps'])])\n",
    "  y.append(d['minutes'])\n",
    "\n",
    "mod = linear_model.LinearRegression()\n",
    "mod.fit(X, y)\n",
    "\n",
    "predictions = open(\"predictions_Minutes.txt\", 'w')\n",
    "predictions.write(\"recipe_id,prediction\\n\")\n",
    "for d in readGz(\"testRecipes.json.gz\"):\n",
    "  x = [1,len(d['steps'])]\n",
    "  pred = mod.predict([x])[0]\n",
    "  predictions.write(d['recipe_id'] + ',' + str(pred) + '\\n')\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06a0d5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [(user,recipe) for user,recipe,d in readCSV(\"trainInteractions.csv.gz\")]\n",
    "Train = dataset[:150000]\n",
    "Valid = dataset[150000:]\n",
    "\n",
    "itemsPerUser = defaultdict(set)\n",
    "usersPerItem = defaultdict(set)\n",
    "\n",
    "for user, recipe in dataset:\n",
    "    itemsPerUser[user].add(recipe)\n",
    "    usersPerItem[recipe].add(user)\n",
    "\n",
    "allRecipes = []\n",
    "for d in readGz(\"trainRecipes.json.gz\"):\n",
    "    allRecipes.append(d['recipe_id'])\n",
    "\n",
    "extra = []\n",
    "for user,recipe in Valid:\n",
    "    rand = random.choice(allRecipes)\n",
    "    while rand in itemsPerUser[user]:\n",
    "        rand = random.choice(allRecipes)\n",
    "    extra.append((user, rand))\n",
    "Valid = Valid + extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33868672",
   "metadata": {},
   "outputs": [],
   "source": [
    "ValidY = [1]*100000 + [0]*100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03c7fbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "itemsPerUserTrain = defaultdict(set)\n",
    "usersPerItemTrain = defaultdict(set)\n",
    "\n",
    "for user, recipe in Train:\n",
    "    itemsPerUserTrain[user].add(recipe)\n",
    "    usersPerItemTrain[recipe].add(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a87e3f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2)) \n",
    "    denom = len(s1.union(s2))\n",
    "    if denom == 0:\n",
    "        return 0\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "672b4e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151462"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predictions = [predict(user, recipe) for (user, recipe) in Valid]\n",
    "\n",
    "recipeCount = defaultdict(int)\n",
    "totalCooked = 0\n",
    "\n",
    "for user,recipe,_ in readCSV(\"trainInteractions.csv.gz\"):\n",
    "  recipeCount[recipe] += 1\n",
    "  totalCooked += 1\n",
    "\n",
    "mostPopular = [(recipeCount[x], x) for x in recipeCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "  count += ic\n",
    "  return1.add(i)\n",
    "  if count > 0.75 * totalCooked: break\n",
    "\n",
    "len(mostPopular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5c36623",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (962575869.py, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/wx/ylj8z3c97w5c7531c6dt4f0c0000gn/T/ipykernel_68525/962575869.py\"\u001b[0;36m, line \u001b[0;32m14\u001b[0m\n\u001b[0;31m    if len(itemsPerUser[user])>:\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "mostPopular = [(recipeCount[x], x) for x in recipeCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "  count += ic\n",
    "  return1.add(i)\n",
    "  if count > 0.75 * totalCooked: break\n",
    "\n",
    "preds = []\n",
    "for user, recipe in Valid[95000:105000]:\n",
    "    if len(itemsPerUser[user])>:\n",
    "        preds.append(1);\n",
    "    else:\n",
    "        preds.append(0);\n",
    "        \n",
    "accuracy = [not a^b for (a,b) in zip(preds, ValidY[95000:105000])]\n",
    "print(\"q2:\", sum(accuracy) / len(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c6b7ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_id': '88348277',\n",
       " 'recipe_id': '03969194',\n",
       " 'date': '2004-12-23',\n",
       " 'rating': '5'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [d for user,recipe,d in readCSV(\"trainInteractions.csv.gz\")]\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dff2713b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = [d for d in readGz(\"trainRecipes.json.gz\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfe3796b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingPerRecipe = defaultdict(set)\n",
    "\n",
    "for d in readGz(\"trainRecipes.json.gz\"):\n",
    "    for i in d['ingredients']:\n",
    "        ingPerRecipe[d['recipe_id']].add(i)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1c8aeeea",
   "metadata": {},
   "source": [
    "pd1 = pd[:5000]\n",
    "print(sum(pd1)/len(pd1))\n",
    "pd2 = pd[5000:]\n",
    "print(sum(pd2)/len(pd2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d6585b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpUser = {}\n",
    "for u in itemsPerUser:\n",
    "    mpUser[u] = len(itemsPerUser[u])\n",
    "\n",
    "#similarities.sort(reverse=True)\n",
    "#mpUser = sorted(mpUser, key=lambda s: (-s[0]))\n",
    "mpUser = sorted(mpUser.items(), key=lambda x: x[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89141c31",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wx/ylj8z3c97w5c7531c6dt4f0c0000gn/T/ipykernel_68525/1874388144.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmpUser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmpUser\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mreturnU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.735666\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtotalCooked\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "returnU = set()\n",
    "count = 0\n",
    "for u in mpUser:\n",
    "  count += mpUser[u]\n",
    "  returnU.add(u)\n",
    "  if count > 0.735666 * totalCooked: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc2a4973",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pct' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wx/ylj8z3c97w5c7531c6dt4f0c0000gn/T/ipykernel_68525/2407554389.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m151400\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'00068256'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pct' is not defined"
     ]
    }
   ],
   "source": [
    "list(pct)[151400:]\n",
    "pct['00068256']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd50064b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalCooked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5419518",
   "metadata": {},
   "outputs": [],
   "source": [
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "  count += ic\n",
    "  return1.add(i)\n",
    "  if count > 0.735666 * totalCooked: break\n",
    "\n",
    "pct = {}\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    pct[i] = count / totalCooked\n",
    "    \n",
    "def feat(user, recipe):\n",
    "    similarities = []\n",
    "    f = [0, 0]\n",
    "    for r in itemsPerUser[user]:\n",
    "        if r==recipe: continue\n",
    "        sim = Jaccard(usersPerItem[recipe], usersPerItem[r])\n",
    "        similarities.append(sim)\n",
    "    if len(similarities)==0: return [0,0]\n",
    "    avg=sum(similarities)/len(similarities)\n",
    "    m=max(similarities)\n",
    "    return [avg, m]\n",
    "\n",
    "def feat3(user, recipe):\n",
    "    if recipe in return1: return 1\n",
    "    similarities = []\n",
    "    for r in itemsPerUser[user]:\n",
    "        if r==recipe: continue\n",
    "        sim = Jaccard(usersPerItem[recipe], usersPerItem[r])\n",
    "        similarities.append(sim)\n",
    "    if(len(similarities)==0): return 0\n",
    "    avg=sum(similarities)/len(similarities)\n",
    "    return avg\n",
    "\n",
    "def feat1(user, recipe):\n",
    "    #if recipe in return1: return 1\n",
    "    maxSim = 0\n",
    "    maxSim1 = 0\n",
    "    for r in itemsPerUser[user]:\n",
    "        if r==recipe: continue\n",
    "        sim = Jaccard(usersPerItem[recipe], usersPerItem[r])\n",
    "        if sim > maxSim: maxSim = sim\n",
    "        sim2 = Jaccard(ingPerRecipe[recipe], ingPerRecipe[r])\n",
    "        if sim2 > maxSim1: maxSim1 = sim2\n",
    "        ## new recipe cold start\n",
    "#         if len(usersPerItem[recipe])==0: \n",
    "#             sim2 = Jaccard(ingPerRecipe[recipe], ingPerRecipe[r])\n",
    "#             if sim2 > maxSim: maxSim = sim2\n",
    "#         else:\n",
    "#             sim = Jaccard(usersPerItem[recipe], usersPerItem[r])\n",
    "#             if sim > maxSim: maxSim = sim\n",
    "#     return maxSim\n",
    "    f = 0\n",
    "    if recipe in pct: f = pct[recipe]\n",
    "    #return [f, (recipe in return1), maxSim, maxSim1, 1]\n",
    "    return [f, maxSim, maxSim1, 1]\n",
    "\n",
    "def feat2(user, recipe):\n",
    "#     if recipe in pct: return [1, pct[recipe]]\n",
    "#     else: return [1, 0]\n",
    "    if recipe in return1: return [1, 1]\n",
    "    return [1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4ab428e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a8b0967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "negTrain = []\n",
    "for user,recipe in Train[:10000]:\n",
    "    rand = random.choice(allRecipes)\n",
    "    while rand in itemsPerUser[user]:\n",
    "        rand = random.choice(allRecipes)\n",
    "    negTrain.append((user, rand))\n",
    "len(negTrain)\n",
    "\n",
    "trainSet = Train[:10000] + negTrain\n",
    "print(len(trainSet))\n",
    "\n",
    "X = [feat1(user, recipe) for (user, recipe) in trainSet]\n",
    "Y = [1]*10000 + [0]*10000\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16ec0674",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done fit\n",
      "done predict\n",
      "0.94315\n"
     ]
    }
   ],
   "source": [
    "mod = KNeighborsClassifier(n_neighbors=100)\n",
    "mod.fit(X,Y)\n",
    "print(\"done fit\")\n",
    "#mod = linear_model.LogisticRegression(class_weight='balanced')\n",
    "#mod.fit(X,Y)\n",
    "\n",
    "xValid = [feat1(user, recipe) for (user, recipe) in Valid[90000:110000]]\n",
    "pds = mod.predict(xValid)\n",
    "print(\"done predict\")\n",
    "\n",
    "accuracy = [not a^b for (a,b) in zip(pds, ValidY[90000:110000])]\n",
    "print(sum(accuracy)/len(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55f5d253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10645"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aaaa02fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:63: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to convert array of bytes/strings into decimal numbers with dtype='numeric'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'list'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    709\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wx/ylj8z3c97w5c7531c6dt4f0c0000gn/T/ipykernel_68525/1240949973.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mxValid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecipe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecipe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mValid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxValid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m^\u001b[0m\u001b[0mb\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValidY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mdata\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    710\u001b[0m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    713\u001b[0m                     \u001b[0;34m\"Unable to convert array of bytes/strings \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m                     \"into decimal numbers with dtype='numeric'\") from e\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to convert array of bytes/strings into decimal numbers with dtype='numeric'"
     ]
    }
   ],
   "source": [
    "xValid = [[1, feat1(user, recipe)] for (user, recipe) in Valid]\n",
    "pds = mod.predict(xValid)\n",
    "accuracy = [not a^b for (a,b) in zip(pds, ValidY)]\n",
    "print(sum(accuracy)/len(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9672274b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5cf65121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800000\n",
      "0.8237\n"
     ]
    }
   ],
   "source": [
    "negTrain = []\n",
    "for user,recipe in Train:\n",
    "    rand = random.choice(allRecipes)\n",
    "    while rand in itemsPerUser[user]:\n",
    "        rand = random.choice(allRecipes)\n",
    "    negTrain.append((user, rand))\n",
    "len(negTrain)\n",
    "\n",
    "trainSet = Train + negTrain\n",
    "print(len(trainSet))\n",
    "\n",
    "X = [[1, feat1(user, recipe)] for (user, recipe) in trainSet]\n",
    "Y = [1]*400000 + [0]*400000\n",
    "\n",
    "\n",
    "#mod = KNeighborsClassifier(n_neighbors=3)\n",
    "mod = linear_model.LogisticRegression(class_weight='balanced')\n",
    "mod.fit(X,Y)\n",
    "\n",
    "xValid = [[1, feat1(user, recipe)] for (user, recipe) in Valid[90000:110000]]\n",
    "pds = mod.predict(xValid)\n",
    "accuracy = [not a^b for (a,b) in zip(pds, ValidY[90000:110000])]\n",
    "print(sum(accuracy)/len(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "id": "b3fb4951",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 722,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = linear_model.LogisticRegression(class_weight='balanced')\n",
    "mod.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "862e8837",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5191, 20000)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pds = []\n",
    "\n",
    "predictions = open(\"predictions_Made.txt\", 'w')\n",
    "for l in open(\"stub_Made.txt\"):\n",
    "  if l.startswith(\"user_id\"):\n",
    "    #header\n",
    "    predictions.write(l)\n",
    "    continue\n",
    "  u,i = l.strip().split('-')\n",
    "  test = feat1(u, i)\n",
    "  pd = mod.predict([test])[0]\n",
    "  pds.append(pd)\n",
    "  predictions.write(u + '-' + i + \",\" + str(pd) + \"\\n\")\n",
    "\n",
    "predictions.close()\n",
    "\n",
    "print(\"done\")\n",
    "sum(pds), len(pds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "4862ede4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5226, 20000)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pds), len(pds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5f8b6684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "id": "47f7ea54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1]"
      ]
     },
     "execution_count": 723,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "id": "656138e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82"
      ]
     },
     "execution_count": 724,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xTest = [[1, feat(user, recipe), feat2(user, recipe)] for (user, recipe) in Train]\n",
    "# yTest = [1]*400000\n",
    "\n",
    "pds = mod.predict(X)\n",
    "accuracy = [not a^b for (a,b) in zip(pds, Y)]\n",
    "sum(accuracy)/len(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "id": "e117fd56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8157"
      ]
     },
     "execution_count": 728,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xValid = [[1, feat1(user, recipe), feat2(user, recipe)] for (user, recipe) in Valid[95000:105000]]\n",
    "pds = mod.predict(xValid)\n",
    "accuracy = [not a^b for (a,b) in zip(pds, ValidY[95000:105000])]\n",
    "sum(accuracy)/len(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec656f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "id": "832e1e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pd: 0.68016\n"
     ]
    }
   ],
   "source": [
    "pd = [((recipe in return1)|(predict(user, recipe))) for (user, recipe) in Valid]\n",
    "accuracy = [not a^b for (a,b) in zip(pd, ValidY)]\n",
    "print(\"pd:\", sum(accuracy) / len(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61ab860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(user, recipe):\n",
    "    for r in itemsPerUserTrain[user]:\n",
    "        if r==recipe: return 1\n",
    "        sim = Jaccard(ingPerRecipe[recipe], ingPerRecipe[r]) + Jaccard(usersPerItemTrain[recipe], usersPerItemTrain[r])\n",
    "        if sim > 0.2: return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "867bbd47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "4541fcbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pd2: 0.745885\n"
     ]
    }
   ],
   "source": [
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "  count += ic\n",
    "  return1.add(i)\n",
    "  if count > 0.73 * totalCooked: break\n",
    "\n",
    "pd2 = [(recipe in return1) for (user, recipe) in Valid]\n",
    "accuracy2 = [not a^b for (a,b) in zip(pd2, ValidY)]\n",
    "print(\"pd2:\", sum(accuracy2) / len(accuracy2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "286001da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q3: 0.67587\n"
     ]
    }
   ],
   "source": [
    "pd = [((recipe in return1)|(predict(user, recipe))) for (user, recipe) in Valid]\n",
    "accuracy = [not a^b for (a,b) in zip(pd, ValidY)]\n",
    "print(\"q3:\", sum(accuracy) / len(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "983e7bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "c2e3b0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "  count += ic\n",
    "  return1.add(i)\n",
    "  if count > 0.75 * totalCooked: break\n",
    "\n",
    "predictions = open(\"predictions_Made.txt\", 'w')\n",
    "for l in open(\"stub_Made.txt\"):\n",
    "  if l.startswith(\"user_id\"):\n",
    "    #header\n",
    "    predictions.write(l)\n",
    "    continue\n",
    "  u,i = l.strip().split('-')\n",
    "  if i in return1:\n",
    "    predictions.write(u + '-' + i + \",1\\n\")\n",
    "  else:\n",
    "    predictions.write(u + '-' + i + \",\" + str(predict(u,i)) + \"\\n\")\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "2bd3bf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = []\n",
    "for r in itemsPerUserTrain[data[1]['user_id']]:\n",
    "    for q in itemsPerUserTrain[data[1]['user_id']]:\n",
    "        if r==q: continue\n",
    "        sim = Jaccard(ingPerRecipe[q], ingPerRecipe[r])\n",
    "        similarities.append((sim, q, r))\n",
    "#similarities.sort(reverse=True)\n",
    "similarities = sorted(similarities, key=lambda s: (-s[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "1e126be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(itemsPerUserTrain[data[1]['user_id']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc5c1b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "4520948f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cloves', 'milk', 'sugar', 'tea leaves', 'water'}"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingPerRecipe['90743062']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "7ef5b888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'milk', 'sugar', 'tea leaves', 'water'}"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingPerRecipe['69440641']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e066d38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db3e70e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bfbb2e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for d in readGz(\"trainRecipes.json.gz\"):\n",
    "    data.append(d)\n",
    "    \n",
    "NTrain = (9*len(data))//10\n",
    "dataTrain = data[:NTrain]\n",
    "\n",
    "sp = set(string.punctuation)\n",
    "\n",
    "wordCount = defaultdict(int)\n",
    "for d in data:\n",
    "    r = ''.join([c for c in d['steps'].lower() if not c in sp])\n",
    "    for w in r.split():\n",
    "        wordCount[w] += 1\n",
    "\n",
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "\n",
    "NW = 1000\n",
    "\n",
    "words = [x[1] for x in counts[:NW]]\n",
    "\n",
    "wordId = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42f41224",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = defaultdict(int)\n",
    "for d in data:\n",
    "    r = ''.join([c for c in d['steps'].lower() if not c in sp])\n",
    "    for w in set(r.split()):\n",
    "        df[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea72eb52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'bakesale betty s fried chicken sandwich',\n",
       " 'minutes': 105,\n",
       " 'contributor_id': '87853888',\n",
       " 'submitted': '2008-02-22',\n",
       " 'steps': 'season chicken breasts with kosher salt\\tlet sit at least 5 minutes\\tfill a wide , shallow nonreactive bowl or casserole dish with buttermilk\\tadd the chicken and soak in the refrigerator for 1 hour up to overnight\\tfor the vinaigrette: combine mustard , vinegar and salt in a bowl\\tslowly whisk in olive oil until well blended\\tfor the coleslaw: macerate onions in the cup of red wine vinegar , and let sit at least 20 minutes\\tremove onions and discard vinegar\\ttoss onions with jalapeno , parsley , cabbage and salt\\ttoss with vinaigrette until evenly coated\\tto fry chicken: pour vegetable oil into a large stockpot\\tdo not fill up more than halfway , or the oil could splatter\\tbring oil up to 365 , using a digital thermometer / candy thermometer to monitor the heat\\tprepare the the breading while waiting for oil to heat up\\tin a wide shallow bowl , mix flour , cayenne , salt and pepper\\tpull a chicken breast out of the buttermilk one by one , letting excess drip off , and dredge completely in flour\\tto create a thick crust , place in buttermilk and dredge in flour a second time\\tdo not drain or shake off excess buttermilk or flour during the breading process\\twhen the oil is at 365 , carefully place chicken pieces into oil one by one\\tlet it cook for a minute before disturbing chicken , then help it swim in the oil with tongs , until it is evenly cooked , about 5-7 minutes\\tremove chicken from oil and drain on paper towels\\tseason immediately with salt\\tfor the sandwich: place fried chicken breast on bottom of torpedo roll and top generously with coleslaw\\tper serving: 995 calories , 52 g protein , 63 g carbohydrate , 58 g fat , 95 mg cholesterol , 1 , 497 mg sodium , 6 g fiber',\n",
       " 'description': \"from one of my favorite restaurants in oakland. grabbed this recipe from muffintop's blog when i got a hankering. also made this sandwich using fried tilapia. still good but i found that all i really wanted to eat was the coleslaw filling. hope you have an appetite cause this is one huge sandwich.\",\n",
       " 'ingredients': ['boneless skinless chicken breasts',\n",
       "  'kosher salt',\n",
       "  'buttermilk',\n",
       "  'dijon mustard',\n",
       "  'red wine vinegar',\n",
       "  'extra virgin olive oil',\n",
       "  'red onion',\n",
       "  'jalapenos',\n",
       "  'parsley',\n",
       "  'green cabbage',\n",
       "  'all-purpose flour',\n",
       "  'cayenne pepper',\n",
       "  'fresh ground pepper',\n",
       "  'vegetable oil',\n",
       "  'rolls'],\n",
       " 'recipe_id': '48248749'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev = data[9] # Query review\n",
    "rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17970b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = defaultdict(int)\n",
    "r = ''.join([c for c in rev['steps'].lower() if not c in sp])\n",
    "for w in r.split():\n",
    "    # Note = rather than +=, different versions of tf could be used instead\n",
    "    tf[w] = 1\n",
    "    \n",
    "tfidf = dict(zip(words,[tf[w] * math.log2(len(data) / df[w]) for w in words]))\n",
    "tfidfQuery = [tf[w] * math.log2(len(data) / df[w]) for w in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66ae6676",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxTf = [(tf[w],w) for w in words]\n",
    "maxTf.sort(reverse=True)\n",
    "maxTfIdf = [(tfidf[w],w) for w in words]\n",
    "maxTfIdf.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "26272fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7.418581259905156, 'candy'),\n",
       " (7.092955525127201, 'jalapeno'),\n",
       " (6.856423725257857, 'pull'),\n",
       " (6.704253469418681, 'thermometer'),\n",
       " (6.7035014782414315, 'sandwich'),\n",
       " (6.6997473906667695, 'dredge'),\n",
       " (6.68186251235447, 'wide'),\n",
       " (6.6518129136030675, 'halfway'),\n",
       " (6.493296513199343, 'generously'),\n",
       " (6.330029893384327, 'during')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxTfIdf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5ca1fab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.418581259905156"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(tfidfQuery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aa8aaef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cosine(x1,x2):\n",
    "    numer = 0\n",
    "    norm1 = 0\n",
    "    norm2 = 0\n",
    "    for a1,a2 in zip(x1,x2):\n",
    "        numer += a1*a2\n",
    "        norm1 += a1**2\n",
    "        norm2 += a2**2\n",
    "    if norm1*norm2:\n",
    "        return numer / math.sqrt(norm1*norm2)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c3ba902f",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = []\n",
    "for rev2 in data:\n",
    "    tf = defaultdict(int)\n",
    "    r = ''.join([c for c in rev2['steps'].lower() if not c in sp])\n",
    "    for w in r.split():\n",
    "        # Note = rather than +=\n",
    "        tf[w] = 1\n",
    "    tfidf2 = [tf[w] * math.log2(len(data) / df[w]) for w in words]\n",
    "    similarities.append((Cosine(tfidfQuery, tfidf2), rev2['steps']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2510dc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d688e147",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.0,\n",
       "  'season chicken breasts with kosher salt\\tlet sit at least 5 minutes\\tfill a wide , shallow nonreactive bowl or casserole dish with buttermilk\\tadd the chicken and soak in the refrigerator for 1 hour up to overnight\\tfor the vinaigrette: combine mustard , vinegar and salt in a bowl\\tslowly whisk in olive oil until well blended\\tfor the coleslaw: macerate onions in the cup of red wine vinegar , and let sit at least 20 minutes\\tremove onions and discard vinegar\\ttoss onions with jalapeno , parsley , cabbage and salt\\ttoss with vinaigrette until evenly coated\\tto fry chicken: pour vegetable oil into a large stockpot\\tdo not fill up more than halfway , or the oil could splatter\\tbring oil up to 365 , using a digital thermometer / candy thermometer to monitor the heat\\tprepare the the breading while waiting for oil to heat up\\tin a wide shallow bowl , mix flour , cayenne , salt and pepper\\tpull a chicken breast out of the buttermilk one by one , letting excess drip off , and dredge completely in flour\\tto create a thick crust , place in buttermilk and dredge in flour a second time\\tdo not drain or shake off excess buttermilk or flour during the breading process\\twhen the oil is at 365 , carefully place chicken pieces into oil one by one\\tlet it cook for a minute before disturbing chicken , then help it swim in the oil with tongs , until it is evenly cooked , about 5-7 minutes\\tremove chicken from oil and drain on paper towels\\tseason immediately with salt\\tfor the sandwich: place fried chicken breast on bottom of torpedo roll and top generously with coleslaw\\tper serving: 995 calories , 52 g protein , 63 g carbohydrate , 58 g fat , 95 mg cholesterol , 1 , 497 mg sodium , 6 g fiber'),\n",
       " (0.3491743217179276,\n",
       "  'make the dredge: in a large bowl , combine the flour , seasoning , baking powder , and pepper\\tfry the chicken: prepare a deep-fryer or fill a large pot halfway with oil and heat to 355f to 360f dredge the chicken in the flour mixture , shake off the excess , and fry until the chicken is dark brown and the crust is brittle , 16 to 18 minutes\\tdrain on paper towels and season with salt to taste'),\n",
       " (0.34340682571978326,\n",
       "  'in a deep bowl mix together buttermilk , pepper sauce , and mashed garlic\\tcut chicken breasts in half lengthwise so that they are in strips roughly 1 inch wide and 4-7 inches long\\tadd chicken to buttermilk , pepper , garlic mix and stir so that chicken is well coated\\tcover the bowl and marinate in the refrigerator several hours or overnight\\tremove chicken from refrigerator about 1 / 2 hour before cooking\\tin a shallow dish mix together the all purpose flour , oregano , garlic powder , paprika , cayenne , salt , and ground pepper\\texact amounts of spices can be adjusted to personal tastes\\tremove chicken from buttermilk mixture one piece at a time shake off excess liquid and then toss into flour mixture to coat\\tplace each piece on a clean dry baking pan\\twhen all pieces are coated , dip each piece , one at a time again , into buttermilk and toss again in flour mixture , remove and set in back into baking pan\\tpour about 1 1 / 2 inches of vegetable oil into a heavy skillet or use a deep fryer filled with oil , and heat oil to 360 degrees\\tcarefully drop pieces of chicken a few at a time into hot oil and cook about 3-4 minutes until pieces are golden brown\\tdo not add too many pieces at one time or the oil temperature will drop too low\\tremove chicken from hot oil and place on clean paper towels to drain\\tthese serve immediately or allow to cool to room temperature\\tfor extra spicy chicken increase amount of cayenne pepper in flour mixture'),\n",
       " (0.3433741472423145,\n",
       "  'whisk together 1 quart of the buttermilk , 2 tablespoons salt and the chili de arbol in a large bowl or large baking dish\\tadd the chicken , turn to coat , cover and refrigerate for at least 4 hours or overnight\\tplace the remaining 2 cups of buttermilk in a bowl\\tstir together the flour , garlic and onion powders , paprika and cayenne in a large bowl and divide among 2 shallow platters and season generously with salt and pepper\\tdrain the chicken in a colander and pat it dry\\tdredge the pieces a few at a time in the flour mixture and pat off excess , then dip in the buttermilk and allow excess to drain off\\tdredge in the second plate of flour and pat off the excess\\tput the chicken pieces on a baking rack set over a baking sheet while the oil heats\\tpour about 3 inches of oil into a deep cast iron skillet\\tthe oil should not come more than half way up the sides of the pot\\tput the pot over medium-high heat and heat the oil to 375f on a deep-fry thermometer\\tworking in batches , add the chicken pieces to the hot oil , 3 or 4 at a time and fry , turning the pieces occasionally , until evenly golden brown and cooked through , about 20 minutes\\tremove from the oil with a slotted spoon and transfer to a rack to drain\\trepeat to cook the remaining pieces\\tserve hot drizzled with the ancho honey , if desired\\tif making ancho honey , whisk together honey , chili powder and salt in a bowl , and drizzle over the chicken'),\n",
       " (0.33363741548007614,\n",
       "  'using vegetable peeler , peel lemon\\tin large shallow glass baking dish , place lemon peel strips and 2 tablespoons olive oil\\tadd chicken breast halves and marinate in refrigerator for at least two hours or up to overnight\\tbring a small saucepan of salted water to boil\\tadd corn kernels and simmer 1 minute\\tdrain and set aside\\tmake relish by combining in large bowl the corn , red pepper dice , green pepper dice , yellow pepper dice , onion , garlic and parsley\\tstir well to combine\\tadd remaining 5 tablespoons olive oil and red wine vinegar\\tseason with 1 / 2 teaspoon salt and 1 / 2 teaspoon pepper\\tprepare grill\\tplace chicken breasts on grill and cook until golden brown on one side , about 5 minutes\\tturn chicken breasts , season with remaining salt and pepper and return to grill\\tcontinue cooking until golden and cooked throughout , about 4 to 5 minutes more\\tto serve , slice each chicken breast on the diagonal into 4 or 5 slices\\ttop with relish'),\n",
       " (0.3239689953884161,\n",
       "  'in a large bowl place the buttermilk , hot sauce , 1 1 / 2 teaspoons of the seasoned salt and cut up chicken , cover and refrigerate at least 8 hours or up to 24 hours drain and discard buttermilk mixture\\tin shallow dish combine flour , garlic salt , red pepper , onion powder and remaining 1 / 2 teaspoons seasoned salt\\tdredge chicken in flour mixture and place on wire rack and let sit for 15 minutes\\tin a large cast-iron skillet pour oil to a depth of 3 inches and heat to 350 degrees\\tfry chicken pieces in batches , for 12 to 15 minutes per side or until a thermometer inserted into the thickest part of the chicken registers 165 degrees\\tdrain on a clean wire rack over paper towels\\tenjoy !'),\n",
       " (0.3209748974956421,\n",
       "  'in a large bowl whisk egg\\tadd in buttermilk and 1-1 / 2 teaspoons garlic powder\\tmix to combine\\tadd in chicken breasts , using hands turn to coat completely in the buttermilk\\trefrigerate for at least 5 hours\\tin a shallow bowl combine all breading mixture together until well combined\\tprepare two plates or a jelly-roll pan\\tplace the chicken into a colinder and allow all the buttermilk mixture to drain\\tdredge each chicken breast into the flour mixture until completely coated\\ttransfer to a large plate or jelly-roll pan\\tallow to sit for 15 minutes then lightly coat once again into the flour mixture\\theat oil in a skillet over medium-high heat\\tfry each breast until golden brown and cooked through'),\n",
       " (0.3101548553079662,\n",
       "  \"beat together the eggs , milk and parmigiano-reggiano in a medium bowl until they are a homogenous mixture\\tseason with salt , to taste , and reserve\\tdivide the mozzarella between 4 slices of the white bread\\tput the remaining slices of bread on top of the mozzarella and press to close\\tpreheat the oven to 300 degrees f\\tadd peanut oil to a large wide skillet until it is at least a 1 / 2-inch deep\\theat over medium-high heat to 350 degrees f\\tdredge each sandwich in flour and shake off the excess\\tdip each sandwich generously in the egg / and cheese mixture\\twork in batches , do this process to each sandwich just before frying , it's not a good idea to flour and dip ahead of time\\tsecure each sandwich with toothpicks\\tput the first sandwich in the hot oil\\tremove the toothpicks to turn and insert the toothpicks in the second side\\twhen each sandwich is nice and brown on both sides , remove it from the oil and blot it on paper towels\\tput it on a sheet tray with a rack and keep warm in the preheated oven\\trepeat this process with each of the sandwiches\\tcut the sandwiches diagonally into quarters , arrange on a serving platter and serve with the sauce\\tsauce:\\tin a small saute pan combine the olive oil , garlic and crushed red pepper\\tcook over medium heat until the garlic is golden brown and very aromatic\\tadd the lemon juice and capers and shake to combine\\tswirl in the butter and season with salt , to taste\\ttoss in the parsley and serve immediately\"),\n",
       " (0.30947407010315586,\n",
       "  'with a sharp knife , lightly score both sides of the chicken breasts in a checkerboard pattern\\tlay a sheet of plastic wrap over the breasts and pound until they are about inch thick\\tseason with salt and pepper\\tdredge the chicken in the flour and then dip it in the beaten eggs , shaking to remove excess\\tdip each piece in the flour and egg again an then coat the chicken in the panko\\tin a deep , straight sided saut pan , heat about inch vegetable oil over medium high heat until the oil ripples and simmers in the pan and instantly erupts into lots of bubbles when you dip a corner of the chicken breast into it\\timmediately reduce the heat to medium low and fry the chicken in batches until cooked through and golden on both sides , 4 to 6 minutes per side\\tif the oil seems to cool down to much during frying , increase the heat a little to maintain a steady bubbling action\\tdrain the chicken on paper towels and serve it with abundant shredded cabbage and tonkatsu sauce\\ttonkatsu sauce: in a small saucepan , whisk together the worcestershire , sugar , soy sauce and ketchup\\tbring to a simmer over medium low heat\\treduce the heat to gentle simmer and whisk often until reduced to 1 cup , about 10 minutes\\twhisk in mustard and allspice\\tcool to room temperature\\tthe sauce will keep for 1 week in the refrigerator'),\n",
       " (0.30937864854151087,\n",
       "  'soak chicken in buttermilk in refrigerator for 1 1 / 2 hours\\tdrain\\tcombine flour , salt , garlic powder , cayenne pepper\\tdredge chicken in flour mixture , shake off excess\\tmelt butter in small saucepan on low heat and stir in honey and bring to boil\\tadd pecans and simmer , keep on low heat and cook 15 minutes\\tmeanwhile heat 3 / 4\" oil in skillet and add chicken that has been dredged in the flour mixture and fry until done and crisp\\tpour honey and pecan mixture over the fried chicken breasts and serve')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ff5ebb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0c129cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum):\n",
    "    feat = [0]*len(words)\n",
    "    r = ''.join([c for c in datum['steps'].lower() if not c in sp])\n",
    "    for w in r.split():\n",
    "        if w in words:\n",
    "            feat[wordId[w]] += 1\n",
    "    feat.append(1) # offset\n",
    "    feat.append(len(datum['steps']))\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1d29e65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nf = len(feature(data[0]))\n",
    "\n",
    "X = lil_matrix((len(data), nf))\n",
    "\n",
    "for i in range(len(data)):\n",
    "    #if not (i % 1000):\n",
    "        #print(i)\n",
    "    x = feature(data[i])\n",
    "    for j in range(nf):\n",
    "        if x[j]:\n",
    "            X[i,j] = x[j]\n",
    "\n",
    "y = [d['minutes'] for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff52b253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72795af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = X[:NTrain]\n",
    "yTrain = y[:NTrain]\n",
    "Xvalid = X[NTrain:]\n",
    "Yvalid = y[NTrain:]\n",
    "\n",
    "mod = linear_model.LinearRegression()\n",
    "\n",
    "mod.fit(Xtrain, yTrain)\n",
    "\n",
    "pred = mod.predict(Xvalid)\n",
    "sum([x**2 for x in (Yvalid - pred)]) / len(Yvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bb8c629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "78b76952",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ['The sky is blue.','The sun is bright.']\n",
    "test = ['The sun in the sky is bright', 'We can see the shining sun, the bright sun.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5661510c",
   "metadata": {},
   "outputs": [],
   "source": [
    "countvectorizer = CountVectorizer(analyzer= 'word', stop_words='english')\n",
    "tfidfvectorizer = TfidfVectorizer(analyzer='word',stop_words= 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "edce23c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_wm = countvectorizer.fit_transform(train)\n",
    "tfidf_wm = tfidfvectorizer.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "25bfcf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tokens = countvectorizer.get_feature_names()\n",
    "tfidf_tokens = tfidfvectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d70bbcfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blue', 'bright', 'sky', 'sun']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1cab67a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blue', 'bright', 'sky', 'sun']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6b91d76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_countvect = pd.DataFrame(data = count_wm.toarray(),index = ['Doc1','Doc2'],columns = count_tokens)\n",
    "df_tfidfvect = pd.DataFrame(data = tfidf_wm.toarray(),index = ['Doc1','Doc2'],columns = tfidf_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "22d56844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectorizer\n",
      "\n",
      "      blue  bright  sky  sun\n",
      "Doc1     1       0    1    0\n",
      "Doc2     0       1    0    1\n",
      "\n",
      "TD-IDF Vectorizer\n",
      "\n",
      "          blue    bright       sky       sun\n",
      "Doc1  0.707107  0.000000  0.707107  0.000000\n",
      "Doc2  0.000000  0.707107  0.000000  0.707107\n"
     ]
    }
   ],
   "source": [
    "print(\"Count Vectorizer\\n\")\n",
    "print(df_countvect)\n",
    "print(\"\\nTD-IDF Vectorizer\\n\")\n",
    "print(df_tfidfvect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3669ea72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse Matrix form of test data : \n",
      "\n",
      "[[0 1 1 1]\n",
      " [0 1 0 2]]\n"
     ]
    }
   ],
   "source": [
    "terms = countvectorizer.fit_transform(train)\n",
    "term_vectors  = countvectorizer.transform(test)\n",
    "print(\"Sparse Matrix form of test data : \\n\")\n",
    "print(term_vectors.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7c93dd56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TD-IDF Vectorizer\n",
      "\n",
      "      blue    bright      sky       sun\n",
      "Doc1   0.0  0.577350  0.57735  0.577350\n",
      "Doc2   0.0  0.447214  0.00000  0.894427\n"
     ]
    }
   ],
   "source": [
    "tm = tfidfvectorizer.transform(test)\n",
    "df_tfidfvect = pd.DataFrame(data = tm.toarray(),index = ['Doc1','Doc2'],columns = tfidf_tokens)\n",
    "print(\"\\nTD-IDF Vectorizer\\n\")\n",
    "print(df_tfidfvect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4b8a8c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse Matrix form of test data : \n",
      "\n",
      "[[0 1 1 1]\n",
      " [0 1 0 2]]\n"
     ]
    }
   ],
   "source": [
    "countvectorizer = CountVectorizer(analyzer='word' , stop_words='english')\n",
    "terms = countvectorizer.fit_transform(train)\n",
    "term_vectors  = countvectorizer.transform(test)\n",
    "print(\"Sparse Matrix form of test data : \\n\")\n",
    "print(term_vectors.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2716d477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 1]\n",
      " [0 1 0 2]]\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfTransformer(norm='l2')\n",
    "term_vectors.todense()\n",
    "print(term_vectors.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a3061014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vector of idf \n",
      "\n",
      "[2.09861229 1.         1.40546511 1.        ]\n",
      "\n",
      "Final tf-idf vectorizer matrix form :\n",
      "\n",
      "[[0.         0.50154891 0.70490949 0.50154891]\n",
      " [0.         0.4472136  0.         0.89442719]]\n"
     ]
    }
   ],
   "source": [
    "tfidf.fit(term_vectors)\n",
    "tf_idf_matrix = tfidf.transform(term_vectors)\n",
    "print(\"\\nVector of idf \\n\")\n",
    "print(tfidf.idf_)\n",
    "print(\"\\nFinal tf-idf vectorizer matrix form :\\n\")\n",
    "print(tf_idf_matrix.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "20d825d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse Matrix form of test data : \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.57735027, 0.57735027, 0.57735027],\n",
       "        [0.        , 0.4472136 , 0.        , 0.89442719]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "train = ('The sky is blue.','The sun is bright.')\n",
    "test = ('The sun in the sky is bright', 'We can see the shining sun, the bright sun.')\n",
    "# instantiate the vectorizer object\n",
    "# use analyzer is word and stop_words is english which are responsible for remove stop words and create word vocabulary\n",
    "tfidfvectorizer = TfidfVectorizer(analyzer='word' , stop_words='english',)\n",
    "tfidfvectorizer.fit(train)\n",
    "tfidf_train = tfidfvectorizer.transform(train)\n",
    "tfidf_term_vectors  = tfidfvectorizer.transform(test)\n",
    "print(\"Sparse Matrix form of test data : \\n\")\n",
    "tfidf_term_vectors.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13b95369",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for d in readGz(\"trainRecipes.json.gz\"):\n",
    "    data.append(d)\n",
    "    \n",
    "NTrain = (9*len(data))//10\n",
    "dataTrain = data[:NTrain]\n",
    "\n",
    "sp = set(string.punctuation)\n",
    "\n",
    "Train = []\n",
    "\n",
    "wordCount = defaultdict(int)\n",
    "for d in data:\n",
    "    r = ''.join([c for c in d['steps'].lower() if not c in sp])\n",
    "    Train.append(r)\n",
    "    for w in r.split():\n",
    "        wordCount[w] += 1\n",
    "\n",
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "\n",
    "NW = 1000\n",
    "\n",
    "words = [x[1] for x in counts[:NW]]\n",
    "\n",
    "wordId = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "867984db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['heat a ridged griddle pan\\tlightly brush the tomato slices and bread with some olive oil\\tcook the tomato slices first  for at least 5 minutes\\twhen they are almost ready  toast the bread in the same pan until well barmarked\\tin the meantime  pour a little olive oil into a small frying pan and crack in the egg\\tallow it to set for a minute or so and add the garlic and chilli\\tcook for a couple of minutes  spooning the hot oil over the egg until cooked to your liking\\tplace the griddled bread on a plate and quickly spoon the tomatoes on top\\tthrow the chives into the egg pan and splash in the balsamic vinegar\\tseason well  then slide the egg on to the tomatoes and drizzle the pan juices on top\\tserve immediately  with a good cup of tea ',\n",
       " 'preheat oven to 350f\\tin 13x9inch baking pan  melt butter in oven\\tsprinkle crumbs evenly over butter\\tpour milk evenly over crumbs\\ttop with remaining ingredients\\tpress down firmly\\tbake 2530 minutes or until lightly browned\\tcool completely  chill if desired  and cut into bars']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea24a825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(stop_words='english')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfvectorizer = TfidfVectorizer(analyzer='word' , stop_words='english',)\n",
    "tfidfvectorizer.fit(Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e1620102",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfidf_train = tfidfvectorizer.transform(Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "757eeffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "efidfv = TfidfVectorizer(analyzer='word',stop_words= 'english')\n",
    "tfidf_wm = efidfv.fit_transform(Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8c54657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<200000x51342 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 8649949 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_wm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0b258b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [d['minutes'] for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b851e56b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10000x49919 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 428533 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vwm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ba134357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l = 0.001, validation MSE = 3511.5993917757532\n"
     ]
    }
   ],
   "source": [
    "trainX = Train[:190000]\n",
    "trainY = y[:190000]\n",
    "twm = efidfv.fit_transform(trainX)\n",
    "\n",
    "valid = Train[190000:]\n",
    "validY = y[190000:]\n",
    "vwm = efidfv.transform(valid)\n",
    "\n",
    "mod = linear_model.Ridge(0.001, fit_intercept=False)\n",
    "mod.fit(twm, trainY)\n",
    "predictValid = mod.predict(vwm)\n",
    "MSEvalid = sum((validY - predictValid)**2)/len(validY)\n",
    "print(\"l = \" + str(l) + \", validation MSE = \" + str(MSEvalid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "967dcf58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l = 1, validation MSE = 2664.0598961028663\n",
      "2664.0598961028663  ,  1\n"
     ]
    }
   ],
   "source": [
    "bestModel = None\n",
    "bestVal = None\n",
    "bestLamb = None\n",
    "\n",
    "trainX = Train\n",
    "trainY = y\n",
    "twm = efidfv.fit_transform(trainX)\n",
    "\n",
    "valid = Train[190000:]\n",
    "validY = y[190000:]\n",
    "vwm = efidfv.transform(valid)\n",
    "\n",
    "lss = [0.1, 1, 10, 100, 1000, 10000]\n",
    "ls = [1]\n",
    "\n",
    "for l in ls:\n",
    "    mod = linear_model.Ridge(l, fit_intercept=False)\n",
    "    mod.fit(twm, trainY)\n",
    "    predictValid = mod.predict(vwm)\n",
    "    MSEvalid = sum((validY - predictValid)**2)/len(validY)\n",
    "    print(\"l = \" + str(l) + \", validation MSE = \" + str(MSEvalid))\n",
    "    if bestVal == None or MSEvalid < bestVal:\n",
    "        bestVal = MSEvalid\n",
    "        bestModel = mod\n",
    "        bestLamb = l\n",
    "            \n",
    "print(bestVal, ' , ', bestLamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e2d37ec4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dimension mismatch",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_92/1344079765.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbestModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvwm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mMSEvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidY\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpredictValid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"l = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\", validation MSE = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMSEvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \"\"\"\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[0m\u001b[1;32m    222\u001b[0m                                dense_output=True) + self.intercept_\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__matmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    558\u001b[0m             raise ValueError(\"Scalar operands are not allowed, \"\n\u001b[1;32m    559\u001b[0m                              \"use '*' instead\")\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__mul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__rmatmul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0;31m# dense row or column vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dimension mismatch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: dimension mismatch"
     ]
    }
   ],
   "source": [
    "pred = bestModel.predict(vwm)\n",
    "MSEvalid = sum((validY - predictValid)**2)/len(validY)\n",
    "print(\"l = \" + str(l) + \", validation MSE = \" + str(MSEvalid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a793640f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cook-time prediction baseline: Regress based on the length of the instructions\n",
    "\n",
    "Test=[]\n",
    "\n",
    "predictions = open(\"predictions_Minutes.txt\", 'w')\n",
    "predictions.write(\"recipe_id,prediction\\n\")\n",
    "for d in readGz(\"testRecipes.json.gz\"):\n",
    "    r = ''.join([c for c in d['steps'].lower() if not c in sp])\n",
    "    Test = [r]\n",
    "    twm = efidfv.transform(Test)\n",
    "    pred = bestModel.predict(twm)\n",
    "    predictions.write(d['recipe_id'] + ',' + str(pred[0]) + '\\n')\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6c683ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([73.60770004])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twm = efidfv.transform([Train[5]])\n",
    "pred = model.predict(twm)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "179a55f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42e3cb67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['heat a ridged griddle pan\\tlightly brush the tomato slices and bread with some olive oil\\tcook the tomato slices first  for at least 5 minutes\\twhen they are almost ready  toast the bread in the same pan until well barmarked\\tin the meantime  pour a little olive oil into a small frying pan and crack in the egg\\tallow it to set for a minute or so and add the garlic and chilli\\tcook for a couple of minutes  spooning the hot oil over the egg until cooked to your liking\\tplace the griddled bread on a plate and quickly spoon the tomatoes on top\\tthrow the chives into the egg pan and splash in the balsamic vinegar\\tseason well  then slide the egg on to the tomatoes and drizzle the pan juices on top\\tserve immediately  with a good cup of tea ',\n",
       " 'preheat oven to 350f\\tin 13x9inch baking pan  melt butter in oven\\tsprinkle crumbs evenly over butter\\tpour milk evenly over crumbs\\ttop with remaining ingredients\\tpress down firmly\\tbake 2530 minutes or until lightly browned\\tcool completely  chill if desired  and cut into bars']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "00fb7720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c31dc23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 40, 50, 25, 55, 75, 40, 20, 55, 105]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f6f3d1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "761a34e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_tokens = tfidfvectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0720d446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train[0, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "88b3f22c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blanch'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_tokens[454]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "02f2908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "countvectorizer = CountVectorizer(analyzer= 'word', stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "34336523",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = countvectorizer.fit_transform(Train)\n",
    "term_vectors  = countvectorizer.transform(Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2107375a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Sparse Matrix form of test data : \\n\")\n",
    "# print(term_vectors.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41de4702",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
